import pandas as pd
import numpy as np
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score
import matplotlib.pyplot as plt
from scipy.spatial.distance import minkowski
from sklearn.metrics import accuracy_score, confusion_matrix


file_path = r"C:\Users\vvmad\Downloads\5th\ML\Lab Session Data.xlsx"
thyroid_data = pd.read_excel(file_path, sheet_name = 'thyroid0387_UCI')

#A1
non_num_cols = thyroid_data.select_dtypes(exclude=[np.number]).columns
print("columns where there are no numbers or numeric data:", non_num_cols)

thyroid_data_num = thyroid_data.drop(columns=non_num_cols)

x = thyroid_data_num.iloc[:, :-1].values
y = thyroid_data.iloc[:, -1].values 

uniques = np.unique(y)
print("Unique classes in thyroid dataset:", uniques)

label_class1 = uniques[0] 
label_class2 = uniques[1] 

class1 = x[y == label_class1]
class2 = x[y == label_class2]

if class1.size > 0 and class2.size > 0:
    centroid1 = np.mean(class1, axis=0)
    centroid2 = np.mean(class2, axis=0)

    sprd1 = np.std(class1, axis=0)
    sprd2 = np.std(class2, axis=0)

    dist = np.linalg.norm(centroid1 - centroid2)

    print(f"Class 1 ('{label_class1}') centroid:", centroid1)
    print(f"Class 2 ('{label_class2}') centroid:", centroid2)
    print(f"Class 1 ('{label_class1}') spread:", sprd1)
    print(f"Class 2 ('{label_class2}') spread:", sprd2)
    print("Distance:", dist)
else:
    print("Either the excel is not clear or it is unfilled.")



#A2
ftr = x[:, 0]

hist, bins = np.histogram(ftr, bins=10)
plt.hist(ftr, bins=10)
plt.title('Feature Histogram')
plt.show()

ftr_mean = np.mean(ftr)
ftr_var = np.var(ftr)

print("Feature Mean:", ftr_mean)
print("Feature Variance:", ftr_var)



#A3
print("Shape of X:", x.shape)

if x.shape[1] > 1:
    ftr1 = x[:, 0]  
    ftr2 = x[:, 1]  
    dists = []

    for r in range(1, 11):
        distt = minkowski(ftr1, ftr2, r)
        dists.append(distt)

    plt.plot(range(1, 11), dists)
    plt.xlabel('Minkowski r')
    plt.ylabel('Distance')
    plt.title('Minkowski Distance for r=1 to 10')
    plt.show()
else:
    print("Less or insufficient values")



#A4
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)
print("Shape of training set x:", x_train.shape)
print("Shape of testing set y:", x_test.shape)
print("Shape of training set y:", y_train.shape)
print("Shape of testing set y:", y_test.shape)



#A5
knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(x_train, y_train)



#A6
acc = knn.score(x_test, y_test)
print("kNN Accuracy:", acc)



#A7
print("Class distribution in training set:", np.unique(y_train, return_counts=True))
print("Accuracy:", accuracy_score(y_test, predictions))
print("Confusion Matrix:\n", confusion_matrix(y_test, predictions))
preds = knn.predict(x_test)
print("Predictions:", preds)




#A8
accs = []

for k in range(1, 12):
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(x_train, y_train)
    acc = knn.score(x_test, y_test)
    accs.append(acc)

plt.plot(range(1, 12), accs)
plt.xlabel('k')
plt.ylabel('Accuracy')
plt.title('k-NN Accuracy for varying k')
plt.show()



#A9
conf_mat = confusion_matrix(y_test, predictions) #already printed in A7
prec = precision_score(y_test, preds, average='macro')
recall = recall_score(y_test, preds, average='macro')
f1 = f1_score(y_test, predictions, average='macro')

print("Confusion Matrix:\n", conf_mat)
print("Precision:", prec)
print("Recall:", recall)
print("F1 Score:", f1)
